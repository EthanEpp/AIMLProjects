{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","id":"4fgY33qdBn7j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709528922602,"user_tz":480,"elapsed":282615,"user":{"displayName":"Ethan Epp","userId":"14209136341608637720"}},"outputId":"2f24def2-0405-45a8-c1c0-ec27aff4fc16"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/diffusers\n","  Cloning https://github.com/huggingface/diffusers to /tmp/pip-req-build-lxsbl25e\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/diffusers /tmp/pip-req-build-lxsbl25e\n","  Resolved https://github.com/huggingface/diffusers to commit 2ca264244b3c234c6b12533fc1421182c22a3a53\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.0.dev0) (7.0.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.0.dev0) (3.13.1)\n","Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.0.dev0) (0.20.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.0.dev0) (1.25.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.0.dev0) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.0.dev0) (2.31.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.0.dev0) (0.4.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.27.0.dev0) (9.4.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.0.dev0) (2023.6.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.0.dev0) (4.66.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.0.dev0) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.0.dev0) (4.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.27.0.dev0) (23.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.27.0.dev0) (3.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.27.0.dev0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.27.0.dev0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.27.0.dev0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.27.0.dev0) (2024.2.2)\n","Building wheels for collected packages: diffusers\n","  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for diffusers: filename=diffusers-0.27.0.dev0-py3-none-any.whl size=1947480 sha256=577693aeb051d66940fa6864e5cfaaa5396a8e26346fb5acd798e8f52a27491e\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-9916j8sj/wheels/f7/7d/99/d361489e5762e3464b3811bc629e94cf5bf5ef44dd5c3c4d52\n","Successfully built diffusers\n","Installing collected packages: diffusers\n","Successfully installed diffusers-0.27.0.dev0\n","Cloning into 'diffusers'...\n","remote: Enumerating objects: 56006, done.\u001b[K\n","remote: Counting objects: 100% (116/116), done.\u001b[K\n","remote: Compressing objects: 100% (90/90), done.\u001b[K\n","remote: Total 56006 (delta 59), reused 46 (delta 18), pack-reused 55890\u001b[K\n","Receiving objects: 100% (56006/56006), 38.66 MiB | 8.62 MiB/s, done.\n","Resolving deltas: 100% (40371/40371), done.\n","Collecting accelerate>=0.16.0 (from -r diffusers/examples/dreambooth/requirements.txt (line 1))\n","  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r diffusers/examples/dreambooth/requirements.txt (line 2)) (0.16.0+cu121)\n","Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from -r diffusers/examples/dreambooth/requirements.txt (line 3)) (4.38.1)\n","Collecting ftfy (from -r diffusers/examples/dreambooth/requirements.txt (line 4))\n","  Downloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r diffusers/examples/dreambooth/requirements.txt (line 5)) (2.15.2)\n","Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r diffusers/examples/dreambooth/requirements.txt (line 6)) (3.1.3)\n","Collecting peft==0.7.0 (from -r diffusers/examples/dreambooth/requirements.txt (line 7))\n","  Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (2.1.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (4.66.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (0.4.2)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (0.20.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->-r diffusers/examples/dreambooth/requirements.txt (line 2)) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r diffusers/examples/dreambooth/requirements.txt (line 2)) (9.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (3.2.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (2.1.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r diffusers/examples/dreambooth/requirements.txt (line 3)) (2023.12.25)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r diffusers/examples/dreambooth/requirements.txt (line 3)) (0.15.2)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r diffusers/examples/dreambooth/requirements.txt (line 4)) (0.2.13)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (1.62.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (3.5.2)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (3.20.3)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (3.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r diffusers/examples/dreambooth/requirements.txt (line 6)) (2.1.5)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r diffusers/examples/dreambooth/requirements.txt (line 2)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r diffusers/examples/dreambooth/requirements.txt (line 2)) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r diffusers/examples/dreambooth/requirements.txt (line 2)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->-r diffusers/examples/dreambooth/requirements.txt (line 2)) (2024.2.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r diffusers/examples/dreambooth/requirements.txt (line 5)) (3.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.7.0->-r diffusers/examples/dreambooth/requirements.txt (line 7)) (1.3.0)\n","Installing collected packages: ftfy, accelerate, peft\n","Successfully installed accelerate-0.27.2 ftfy-6.1.3 peft-0.7.0\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->bitsandbytes) (1.25.2)\n","Installing collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.42.0\n","Collecting xformers\n","  Downloading xformers-0.0.24-cp310-cp310-manylinux2014_x86_64.whl (218.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m218.2/218.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.25.2)\n","Collecting torch==2.2.0 (from xformers)\n","  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.0->xformers) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0->xformers)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0->xformers)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0->xformers)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0->xformers)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0->xformers)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0->xformers)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0->xformers)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0->xformers)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0->xformers)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0->xformers)\n","  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0->xformers)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==2.2.0 (from torch==2.2.0->xformers)\n","  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0->xformers)\n","  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.0->xformers) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.0->xformers) (1.3.0)\n","Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers\n","  Attempting uninstall: triton\n","    Found existing installation: triton 2.1.0\n","    Uninstalling triton-2.1.0:\n","      Successfully uninstalled triton-2.1.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.0+cu121\n","    Uninstalling torch-2.1.0+cu121:\n","      Successfully uninstalled torch-2.1.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\n","torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.2.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 triton-2.2.0 xformers-0.0.24\n","Collecting lit\n","  Downloading lit-17.0.6.tar.gz (153 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: lit\n","  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=550aefb31784382ee1781320716bcb2afa00d3d73a3a421d898170ec4a588780\n","  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n","Successfully built lit\n","Installing collected packages: lit\n","Successfully installed lit-17.0.6\n","Collecting colab-xterm\n","  Downloading colab_xterm-0.2.0-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.6/115.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ptyprocess~=0.7.0 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (0.7.0)\n","Requirement already satisfied: tornado>5.1 in /usr/local/lib/python3.10/dist-packages (from colab-xterm) (6.3.2)\n","Installing collected packages: colab-xterm\n","Successfully installed colab-xterm-0.2.0\n"]}],"source":["#@title Install dependencies\n","!pip install git+https://github.com/huggingface/diffusers\n","!git clone https://github.com/huggingface/diffusers\n","!pip install -r diffusers/examples/dreambooth/requirements.txt\n","!pip install bitsandbytes\n","!pip install xformers\n","!pip install lit\n","!pip install colab-xterm"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kkNmWp_TB2Za","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709528931122,"user_tz":480,"elapsed":8523,"user":{"displayName":"Ethan Epp","userId":"14209136341608637720"}},"outputId":"6895f0d7-4afa-4249-a6a4-37db8d4e4f75"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["PosixPath('/root/.cache/huggingface/accelerate/default_config.yaml')"]},"metadata":{},"execution_count":2}],"source":["#@title setup accelerate with floating point 16-bit\n","from accelerate.utils import write_basic_config\n","write_basic_config(mixed_precision=\"fp16\")"]},{"cell_type":"markdown","metadata":{"id":"LkoN3gm23gv5"},"source":["## Log in to HuggingFace"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"g1DZS1P2mLPc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709528955791,"user_tz":480,"elapsed":24673,"user":{"displayName":"Ethan Epp","userId":"14209136341608637720"}},"outputId":"21147fbf-9607-4064-8db7-4df67f5cb449"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Token: \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["!huggingface-cli login"]},{"cell_type":"markdown","metadata":{"id":"LUH6Jx9t3P1g"},"source":["# Mount Google Drive\n","For downloading person instance images and class images to workspace, and storing your model checkpoints output to google drive."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"4Po1D_Q93R1Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709528972362,"user_tz":480,"elapsed":16582,"user":{"displayName":"Ethan Epp","userId":"14209136341608637720"}},"outputId":"2d1b46b6-7d78-4958-c2bf-877bf8b2bad3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"POXRx8hxlPzW"},"source":["## Stable Diffusion"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"lLLKEQBlllE4"},"outputs":[],"source":["#@title Try out stable diffusion model on HuggingFace\n","\n","import torch\n","from diffusers import StableDiffusionPipeline\n","from IPython.display import display\n","\n","model_id = \"CompVis/stable-diffusion-v1-4\" #@param {type:\"string\"}\n","device = \"cuda\"\n","\n","\n","pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n","pipe = pipe.to(device)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"2Tk5J7OBmmfY"},"outputs":[],"source":["prompt = \"A pikachu fine dining with a view to the Eiffel Tower\" #@param {type:\"string\"}\n","image = pipe(prompt).images[0]\n","\n","display(image)"]},{"cell_type":"markdown","metadata":{"id":"K3FohQzkzkXC"},"source":["## Use Microsoft/Promptist to refine prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rs8ROKA7zkXC"},"outputs":[],"source":["# Load Microsoft/Promptist pipeline\n","from transformers import pipeline\n","\n","promptist_pipe = pipeline(\"text-generation\", model=\"microsoft/Promptist\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RkRAH2TPzkXC"},"outputs":[],"source":["prompt = 'A pikachu fine dining with a view to the Eiffel Tower' #@param {type:\"string\"}\n","result = promptist_pipe('A pikachu fine dining with a view to the Eiffel Tower')\n","print(f'Optimized Prompt: {result[0][\"generated_text\"]}')"]},{"cell_type":"markdown","metadata":{"id":"DmHF_pnCzkXC"},"source":["## **NOTE: Restart session to clear RAM for the latter execution.**"]},{"cell_type":"markdown","metadata":{"id":"q2ARUYsL3jwZ"},"source":["## DreamBooth Code setup\n","More details of the training script and parameters can be found in the following links: \\\\\n","https://github.com/huggingface/diffusers/tree/main/examples/dreambooth \\\\\n","https://huggingface.co/docs/diffusers/en/training/dreambooth\n","\n","For guidance of selecting training and inference paramters, you find more information in this link: \\\\\n","https://huggingface.co/blog/dreambooth"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lrdxYqT7FxI"},"outputs":[],"source":["#@title Generate command for training model\n","\n","#@markdown Pre-trained diffusion models from HuggingFace\n","model_name = \"CompVis/stable-diffusion-v1-4\" #@param {type:\"string\"}\n","\n","#@markdown Directory containing your instance images\n","instance_dir = \"/content/instance_dir\" #@param {type:\"string\"}\n","\n","#@markdown Directory containing your class images\n","class_dir = \"/content/class_images\" #@param {type:\"string\"}\n","\n","#@markdown Directory for storing model output and checkpoints\n","output_dir = \"/content/output_dir\" #@param {type:\"string\"}\n","\n","#@markdown Your instance prompt\n","instance_prompt = \"a sks person\" #@param {type:\"string\"}\n","\n","#@markdown Your class prompt\n","class_prompt = \"a person\" #@param {type:\"string\"}\n","\n","#@markdown Number of class images use in training\n","num_class_images = 1500 #@param {type:\"integer\"}\n","\n","#@markdown Training steps use in training\n","max_training_steps = 500 #@param {type:\"integer\"}\n","\n","#@markdown Checkpoint steps (frequency of saving checkpoints)\n","checkpointing_steps = 100 #@param {type:\"integer\"}\n","\n","#@markdown Learning rate use in training\n","learning_rate = 0.000002 #@param {type:\"number\"}\n","\n","#@markdown Resume to checkpoint\n","resume_checkpoint = False #@param {type:\"boolean\"}\n","checkpoint_number = 100 #@param {type:\"number\"}\n","\n","# export directories for current process, needed for later use\n","!export MODEL_NAME=model_name\n","!export INSTANCE_DIR=instance_dir\n","!export CLASS_DIR=class_dir\n","!export OUTPUT_DIR=output_dir\n","!export INSTANCE_PROMPT=instance_prompt\n","!export CLASS_PROMPT=class_prompt\n","\n","# create training command\n","training_command = f'''\n","export MODEL_NAME=\"{model_name}\"\n","export INSTANCE_DIR=\"{instance_dir}\"\n","export CLASS_DIR=\"{class_dir}\"\n","export OUTPUT_DIR=\"{output_dir}\"\n","export INSTANCE_PROMPT=\"{instance_prompt}\"\n","export CLASS_PROMPT=\"{class_prompt}\"\n","export NUM_CLASS_IMAGES={num_class_images}\n","export MAX_TRAIN_STEPS={max_training_steps}\n","export CHECKPOINTING_STEPS={checkpointing_steps}\n","export LEARNING_RATE={learning_rate}\n","\n","accelerate launch --mixed_precision=\"fp16\" \"/content/diffusers/examples/dreambooth/train_dreambooth.py\" \\\\\n","  --pretrained_model_name_or_path=\"$MODEL_NAME\"  \\\\\n","  --train_text_encoder \\\\\n","  --instance_data_dir=\"$INSTANCE_DIR\" \\\\\n","  --class_data_dir=\"$CLASS_DIR\" \\\\\n","  --output_dir=\"$OUTPUT_DIR\" \\\\\n","  --with_prior_preservation \\\\\n","  --prior_loss_weight=1.0 \\\\\n","  --instance_prompt=\"$INSTANCE_PROMPT\" \\\\\n","  --class_prompt=\"$CLASS_PROMPT\" \\\\\n","  --resolution=512 \\\\\n","  --train_batch_size=2 \\\\\n","  --gradient_accumulation_steps=2 \\\\\n","  --gradient_checkpointing \\\\\n","  --use_8bit_adam \\\\\n","  --learning_rate=$LEARNING_RATE \\\\\n","  --lr_scheduler=\"constant\" \\\\\n","  --lr_warmup_steps=0 \\\\\n","  --num_class_images=$NUM_CLASS_IMAGES \\\\\n","  --max_train_steps=$MAX_TRAIN_STEPS \\\\\n","  --checkpointing_steps=$CHECKPOINTING_STEPS \\\\\n","  --enable_xformers_memory_efficient_attention \\\\\n","  --set_grads_to_none '''\n","\n","if(resume_checkpoint):\n","  training_command += f'\\\\\\n  --resume_from_checkpoint=\"{output_dir}/checkpoint-{checkpoint_number}\"'\n","\n","print(training_command)"]},{"cell_type":"markdown","metadata":{"id":"CUpMM1Wh3mZo"},"source":["## Copy-Past-and-Run the above code in this xterm window"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HinvKuIZDr_U"},"outputs":[],"source":["%load_ext colabxterm\n","%xterm"]},{"cell_type":"markdown","metadata":{"id":"823__QN6xfnx"},"source":["Run this block of code during training to avoid Google Colab from timing out. \\\n","NOTE! If you killed this cell, it will also kill the xterm process in the above cell. (Only kill this cell if your training is complete.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kk8b7s_pgJB"},"outputs":[],"source":["#@title Run this code to prevent runtime timeout\n","from time import sleep\n","from datetime import datetime\n","while 1:\n","  print('Preventing runtime timeout... Current time:', datetime.now())\n","  sleep(60)"]},{"cell_type":"markdown","metadata":{"id":"ARMhiW2E36XI"},"source":["## Try out your\n","Test out your model by giving it various prompt. (e.g. \"a sks person with blue hair\", \"a sks person wearing chef outfit\") \\\n","If your model is not affected by your prompt, then most likely, your model has overfitted to the training images. In this case, try out an earlier checkpoint."]},{"cell_type":"markdown","metadata":{"id":"1rs7q7MC4qtA"},"source":["Load model with this cell"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ldjRC2sWnkYq"},"outputs":[],"source":["#@title Load the model currently at the root of the output directory\n","\n","#@markdown scheduler for sampling images during inference (see https://huggingface.co/blog/dreambooth#effect-of-schedulers)\n","scheduler_name = \"DDIM\" #@param [\"DDIM\", \"DPMSolverMultistep\"]\n","\n","#@markdown Resume to checkpoint\n","output_dir = \"/content/output_dir\" #@param {type:\"string\"}\n","checkpoint_number = 300 #@param {type:\"number\"}\n","\n","from diffusers import (\n","    StableDiffusionPipeline,\n","    DPMSolverMultistepScheduler,\n","    DDIMScheduler\n",")\n","import torch\n","\n","checkpoint_dir = f'{output_dir}/checkpoint-{checkpoint_number}'\n","\n","schedulers = {\n","    'DPMSolverMultistep': DPMSolverMultistepScheduler.from_pretrained,\n","    'DDIM': DDIMScheduler.from_pretrained\n","}\n","\n","scheduler = schedulers[scheduler_name]\n","\n","pipe = StableDiffusionPipeline.from_pretrained(output_dir,\n","          scheduler=scheduler(output_dir, subfolder=\"scheduler\"),\n","          torch_dtype=torch.float16\n","        ).to(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"dBaS5aHzrFfh"},"outputs":[],"source":["#@title Generate image from prompt\n","\n","#@markdown Prompt use to generate images\n","prompt = \"a sks person wearing chef uniform\" #@param {type:\"string\"}\n","\n","#@markdown Number of inference steps\n","num_inference_steps = 50 #@param {type:\"integer\"}\n","\n","#@markdown Guidance scale\n","guidance_scale = 7.5 #@param {type:\"number\"}\n","\n","#@markdown Number of image to generate\n","num_images = 3 #@param {type:\"integer\"}\n","\n","from IPython.display import display\n","for _ in range(num_images):\n","  image = pipe(prompt,\n","                num_inference_steps=num_inference_steps,\n","                guidance_scale=guidance_scale\n","               ).images[0]\n","  display(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"FAVdFM50eKCv"},"outputs":[],"source":["#@title Save your fine-tuned model to your huggingface-hub (Code from [HuggingFace Stable Diffusion Dreambooth Concepts Library](https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/sd_dreambooth_training.ipynb) with modifications)\n","\n","#@markdown HuggingFace repository name where the model will be saved to\n","repo_name = \"\" #@param {type:\"string\"}\n","\n","import os\n","from slugify import slugify\n","from huggingface_hub import HfApi, HfFolder, CommitOperationAdd\n","from huggingface_hub import create_repo\n","from IPython.display import display_markdown\n","\n","# some api and huggingface account setup\n","api = HfApi()\n","your_username = api.whoami()[\"name\"]\n","\n","# save the model in the root of the model output folder\n","os.makedirs(\"fp16_model\",exist_ok=True)\n","pipe.save_pretrained(\"fp16_model\")\n","\n","# retrieve your huggingFace repo and upload model\n","repo_id = f\"{your_username}/{slugify(repo_name)}\"\n","\n","\n","with open(HfFolder.path_token, 'r') as fin: hf_token = fin.read();\n","\n","\n","readme_text = f'''---\n","license: creativeml-openrail-m\n","tags:\n","- text-to-image\n","---\n","### Fine-tuned Stable Diffusion via Dreambooth\n","#### model by {api.whoami()[\"name\"]}\n","A fine-tuned Stable Diffusion via Dreambooth\n","'''\n","\n","# Save the readme to a file\n","readme_file = open(\"README.md\", \"w\")\n","readme_file.write(readme_text)\n","readme_file.close()\n","\n","# Save the token identifier to a file\n","text_file = open(\"token_identifier.txt\", \"w\")\n","text_file.close()\n","operations = [\n","  CommitOperationAdd(path_in_repo=\"token_identifier.txt\", path_or_fileobj=\"token_identifier.txt\"),\n","  CommitOperationAdd(path_in_repo=\"README.md\", path_or_fileobj=\"README.md\"),\n","]\n","\n","# create private repo\n","create_repo(repo_id, private=True, token=hf_token)\n","\n","# commit and upload model\n","api.create_commit(\n","  repo_id=repo_id,\n","  operations=operations,\n","  commit_message=f\"Uploaded fine-tuned model.\",\n","  token=hf_token\n",")\n","api.upload_folder(\n","  folder_path=\"fp16_model\",\n","  path_in_repo=\"\",\n","  repo_id=repo_id,\n","  token=hf_token\n",")\n","\n","\n","print(f'## Your model was saved successfully. [Click here to access it](https://huggingface.co/{repo_id})')"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"lXNqPg_2BOPP"},"outputs":[],"source":["#@title DELETE checkpoint to free up space\n","\n","#@markdown Checkpoint to be deleted\n","delete_confirmation = False #@param {type:\"boolean\"}\n","checkpoint_number = None #@param {type:\"number\"}\n","\n","import shutil\n","\n","if(delete_confirmation):\n","  shutil.rmtree(f'{output_dir}/checkpoint-{checkpoint_number}')\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}